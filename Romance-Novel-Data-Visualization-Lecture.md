**Learning Objectives:**
-- 

* Conduct Rudimentary Exploratory Data Analysis (EDA)
* Generate Simple Plots with Base R
* Build Custom Plots with `ggplot2` to Answer Copmlex Questions

**What Is The Goal of Data Visualization?** 
--
* **Visual Proof**: A great data visualization provides proof that our data shows what we have described in words. You can certainly take what I say at face value, but critically, you should expect me to show it to you. As scientist, we strive to be worthy of our readers' trust and data visualizations can assist with that.

* **Data Storytelling**: A picture is worth 1000 words! If you generate a great visualization it can adequately communicate many pieces of information. Let's say we are looking at trends in sales of different colored widgets: red widgets, blue widgets, green widgets, and yellow widgets. We could plot a single line showing how many people purchased widgets between 2020 and 2025 or I could plot four different lines, each for the sale of different colored widgets. Take a look at these visualizations. What do they tell us about our data? 

<div style="display: flex; justify-content: center;">
  <img src="/images/trends.png" width="1000" alt="Trend-Line">
</div>

The plot on the right shows us that the number of sales for red, blue, and green widgets increases over the 2020-2025 time period, but the sales for yellow widgets decreases! We wouldn't have known that had we not broken down or visualization by the groups within our "Color" variable. By the way, this reversal of trends when looking at subgroups of our variable is known as **Simpson's Paradox**.

* **Presentation Purposes**: A visualization will not only summarize your information, but will clearly communicate your findings in a memorable way. Humans remember things that they see! Some of my earliest memories are not auditory, but rather visual. I remember the color of shirt my Grandma wore when she came to pick me up from shool one day.

**What Makes A Good Visualization?**
--
* **Clear Titles and Axis Labels**: If you generate a histogram, please for the love of all that is good, do not title this histogram, "Histogram" with axes "X" and "Y". If you handed anyone on the street that visualization, they might say that you have made a lovely histogram. Of what? Who is to say. Descriptive titles might be something like, "Distribution of Widget Sale Between 2020-2025" with axis labels "Count" and "Frequency".

* **Clearly Distinguishable Colorblind Friendly Colors**: Choosing colors that are not easily distinguished from other another might mislead a reader. Further, 1 in 12 males are colorblind. Really. Here's a [reference](https://www.nei.nih.gov/eye-health-information/eye-conditions-and-diseases/color-blindness) for that. We will talk about how you can choose colorblind friendly colors later in this lecture.

* **Data Storytelling**: Your visualizations should tell a cohesive story. It's imperitive not to add distracting bells and whitles to your visualizations, rather, focus on the pieces of informtion you want your reader to gain. 

* **Know Your Audience**: Would you show your 5-year-old cousin the same graphic you would show your work collegue? Probably not. Gear your visualizations to the audience who will see them 

**How Can We Create Good Visualizations?**
--
* **Focus on Your Question**: When creating a plot, or series of plots, make sure to focus on our study question. Ask yourself how each figure supports the question you are trying to answer. Taken together all of the plots you generate should 

* **Focus on Your Findings**: If you want to know if more males or females purchsed green widgets, spend some time thinking about which visualization will most adequately help you find the answer to this question.

* **Use Programming**: You came to this workshop for a reason, did you not? Generating figures using a programming language will give you the power to fine tune your visualizations and step outside of conventionally used visualizations that can be generated by point and click tools. Plus, they are PRETTY. 


**What R Tools for Data Visualization Will We Learn About Today?**
* Base R: Some plotting functions, such as `hist()` and `plot()` are built into R and can be accessed without calling special libraries. These are known as base R plotting functions. During this workshop, we will use these base R plotting functions to conduct inital eploratory data analysis (EDA). 

* ggplot2: ggplot2 is a special R library that provides functionality to customize  advanced plots and figures. During today's workshop we will leverage ggplot2 to create publication-ready visualizations from our Romance Novel data set.

**Kaggle - Romance Novel Data Set**
Allow me to get up on my soap box for a moment and expound upon one of the most beautiful aspects of data science. We each bring expertise from our diverse and enriching backgrounds in Finance, Biology, Literature, Art, Anthropology, Physics, and whatever other discipline we fell in love with at the age of 7 while watching a NOVA episode. Developing our data science skills opens the door to research in any of these fields. If you have some data, you bet we can find a visualization or analysis appropriate for that data.  

On the topic of exploring data suited to our interests, I have chosen a romance novel data set for this workshop. It will come to the suprise of no one here that I am not going home and reading Dostoevsky, Thoreau, or even Austen. Nay, I go home and I read garbage. One could argue that I am consuming the equivalent of skittles for my brain and they would be entirely correct. But I am not on this planet with the strict purpose of being useful and productive. I want to enjoy sitting with my hot chocolate and my books. That said, let's take a look at the contents of the data set with which we will be working and with the aim of finding an answer to the following questions:

* Do longer books get better ratings?

*Note: This data set was taken from [Kaggle](https://www.kaggle.com/datasets). Kaggle provides free access to tons of really intersting data! Take a look and play around!*

**Exploratory Data Analysis (EDA)**
--

It is vital to have a clear understanding of the contents of the data set with which we are working before jumping into data visualization. Thus, an initial exploratory data analysis (EDA) should be undertaken to determine the dimensions of the data, row names, column names, data types, and missingness. Let's go ahead and read in our data:

```
##########################################################
#                   LOADING OUR DATA
##########################################################
## Read in data
books <- read.csv("/Users/f002yt8/Documents/GitHub/Romance-Novel-Data-Visualization-Workshop/data/books.csv")

## Some titles are repeated so we will just keep one of the titles fr simplicity 
books <- books[!duplicated(books$title), ]

## Make the first column the book titles 
rownames(books) <- books[,"title"]
books <- subset(books, select = -c(title,X))

## Make sure "books" is a data frame
books <- data.frame(books)

## Let's check and make sure we read in the data correctly
head(books)
```
Now that we have loaded in our data let's have a look at the column names in our data frame. The column names typically contain the variables in our data. For this data set we can expect to find variables for book rating, book length, and author. In the same way if we were looking at a data set with patient information we might see variables for age, sex, white blood cell count, blood pressure, etc. To see the column names all we need to do it apply the function `colnames()`.

```
##########################################################
#                   DATA FRAME VARIABLES
##########################################################

## Column names for our data
colnames(books)
```

Great, for each title in our data we have informaiton on the author, release year, book length, rating, number of ratings, and a short synopsis of the book. I'm curious though, how many books are in this data set? We can use the R functions `dim()` and `str()` to gain an understanding of how much data we have.

```
##########################################################
#                 ASSESSING DATA DIMENSIONS
##########################################################

## Assessing data dimensions
dim(books)

## Taking a look at data dimensions...... and some other information
str(books)
```

Running the `dim()` function returns `1232` and `6` this is the number of rows and columns respectively. So we have 1232 books in our data frame and 6 variables, which we  previously viewed using `colnames()`. We used a second function here, `str()`. The `str()` function means "structure" and provides us with the dimensions of the data frame at the top of the output `'data.frame': 1232 obs. of  6 variables`. But what is all of this other information? The informaiton below the dimensions are previews of the information stored in the data frame. We can see that each of the rows in the output is one of the data frame variables. The data type is indicated after the colon in each row. For example, after `:` the `author`row we see the letters `chr` standing for "character" this means that the data in the `author` column in our data frame are `characters`. The `release.year`, `book.length`,and `number.of.ratings` is coded as `int` standing for "integer". The `rating` is coded as `num` or "numeric". Inserted after the data type, we can see a preview of some of the values in each of the variable columns. Taking a quick look, I can see that `book.length` contains a bunch of "NA" values. It's always good to look at missingness in our data. Let's use a few R functions to determine how many NA values we have in our data. 

```
##########################################################
#                 ASSESSING MISSINGNESS
##########################################################

## Assessing missingness using a for loop

book_columns <- colnames(books)

book_columns <- colnames(books)
for (col in book_columns){
  print(col)
  print(length(which(is.na(books[,col]) == TRUE)))
}
```
Wow! It looks like there are 601 "NA" values in the `book.length` variable. It is important to consider why this might be the case. If I were to guess, I would say that multiple versions of some of these books have been released with varying page lengths so instead of reporting multiple page lengths for differentbook versions, the authors of this data set simply left the length as "NA". In some cases, depending on the data, we might consider imputing NA values, however, this is beyond the scope of today's workshop so we will leave the data frame as is and move on to visualizations with the knowledge that the `book.length` variable has quite a bit of missingness.  

**Base R Visualizations - Let's Eyeball It**
--
At the beginnig of this lecture, I mentioned that base R has some great functions that we can use to take a cursory look at the distribution of our data. I would recommend using base R functions when you initially get a new data set and you are hoping to churn out some preliminary visualizations for your PI or group members for a project. 

*Histograms*
I'm intersted in the system used to rate books in this data set. Using the `hist()` function in base R, we can create a histogram that shows us the distribution of the ratings across all of the titles in our data frame. 

```
##########################################################
#            GENERATING A HISTOGRAM WITH BASE R
##########################################################

## Generate a hisogram of book ratings
hist(books[,"rating"])

## Let's add an appropriate main title as well as x and y axis labels
hist(books[,"rating"], main = "Rating Across All Titles", xlab = "Rating", ylab = "Frequency")

## How about we add some color to this plot
hist(books[,"rating"], main = "Rating Across All Titles", xlab = "Rating", ylab = "Frequency", col = "cornflowerblue")

## Let's get some more ganularity in the distribution
hist(books[,"rating"], main = "Rating Across All Titles", xlab = "Rating", ylab = "Frequency", col = "cornflowerblue", breaks = 30)
```

*Scatter Plot*
In addition to histograms, base R provides functionality to create scatterplots using the `plot()` function. The plot function takes a vector for x values and a vector for y values and plots them together. I'm wondering if we could see any sort of trend between book length and rating? I'll remove any values where there is "NA" for `book.length` before plotting. 

```
##########################################################
#            GENERATING A SCATTERPLOT WITH BASE R
##########################################################

## Drop any rows with NA values in the book.length column
library(tidyr)
books_sub <- books %>% drop_na(book.length)

## Set x and y
x <- books_sub[,"book.length"]
y <- books_sub[,"rating"]

## Plot book length vs. rating
plot(x, y, main = "Book Length vs. Rating", xlab = "Book length (Pages)", ylab = "Rating", col = "darkgreen")

## Increase point size
plot(x, y, main = "Book Length vs. Rating", xlab = "Book length (Pages)", ylab = "Rating", col = "darkgreen", cex = 3)

## Change the shape of the point
plot(x, y, main = "Book Length vs. Rating", xlab = "Book length (Pages)", ylab = "Rating", col = "darkgreen", pch = 25)

## I suppose I can convince myself that there is a linear relationship between rating and length of book
model <- lm(y ~ x) # define a model
abline(model, col = "red", lwd = 2)
plot(x, y, main = "Book Length vs. Rating", xlab = "Book length (Pages)", ylab = "Rating", col = "darkgreen", pch = 25)

```
*Box Plot*
An additional way in which we can explore relationships between two variables is to create a box plot. I'm interested in looking at the distribution of ratings for books between 2010 and 2014. To do so, we will subset of main data frame to contain only data from 2010-2014. We will also convert the `release.year` to a factor, which is a special case of a vector. Finally, we will add color to our box plots. On that note, I would like to introduce you all to [Coolors](https://coolors.co/?home). Coolors is a great resource to help you pick out custom color palettes for your R plots! Or they can help you pick out a new color for your bathroom walls.

```
##########################################################
#            GENERATING A BOXPLOT WITH BASE R
##########################################################

## Subset data to the years 2010-2014
books_sub <- books[which(books$release.year == c(2010, 2011, 2012, 2013, 2014)),]

## Make sure that the source year is coded as a factor
books_sub$release.year <- factor(books_sub$release.year)

## Create box plot
boxplot(rating ~ release.year, 
        data = books_sub, 
        notch = TRUE, 
        col = c("#9AC4F8", "#99EDCC","#CB958E", "#E36588", "#9A275A"),
        main = "Rating Distribution by Year",
        xlab = "Year", ylab = "Rating")

```

Base R functions are quick and easy to use. You can apply the limited number of parameters to these visualization functions and have some half way decent plots to get a general understanding of data distribution. But that's just the thing, we are quite limited to the few parameters provided by base R functions. With base R functions we are typically only able to answer simple questions about our data. However, using `ggplot2` we are able to take a layered approach to data visualization that can help us begin to get at complex questions. 

**Creating Plots with ggplot2**
--
ggplot2 is an R package that leverages a layered coding framework to create visualizations. What do we mean by a "layered coding framework"? In `ggplot2` we have the power to add elements on top of one another in our data set. For example, we might find it helpful to overlay a distribution plot on a point representing an average so that we gain a better understanding of the disribution of our data. Let's take a look at the anatomy of a `ggplot2` plot before we dive into some more complex questions.

The foundation of every `ggplot2` graphic is the data used to construct the plot. As a first step, we will need to pass our rectangular data frame to the `ggplot2 ` argument. 

```
##########################################################
#                BASE OF A GGPLOT PLOT
##########################################################

## We wil proceed downstream by looking at the subset data frame that does not contain NA values for book.length
library(tidyr)
books_sub <- books %>% drop_na(book.length)

## The base of a ggplot2 plot
ggplot(data = books_sub)
```

Now, I will happily bet a couple dollars and say that a few of you in this workshop skipped ahead, ran the above code, and said "This didn't do anything." or "This returned a gray box." You are correct! This line of code shouldn't have returned really anything because we have not specificed the variables we wish to visualize. Let's say we want to replicate the scatter plot we made in base R where we plotted the book length on the x-axis and book rating on the y-axis. 

```
##########################################################
#                     ADD VARAIABLES
##########################################################

## Add variables we would like to plot
ggplot(data = books_sub, mapping = aes(x = book.length, y = rating))
```

You may be wondering at this point, "NOELLE, I STILL DON'T SEE ANY PLOT!?!?!?!" Yes, you shouldn't see any plot quite yet because we have not told `ggplot2` what type of plot we want to generate. To indicate that we would like to create a scatter plot, we have to use the `geom_point()` function. 

```
##########################################################
#                   ADD TYPE OF PLOT
##########################################################

## Add type of plot
ggplot(data = books_sub, mapping = aes(x = book.length, y = rating)) +
geom_point()
```
Finally! We have a plot, but it's hedious. We can change the color of the points and the transparency of the points within the `geom_point()` function. 

```
##########################################################
#         CHANGING DISCRETE COLOR OF ALL POINTS
##########################################################

## Add type of plot
ggplot(data = books_sub, mapping = aes(x = book.length, y = rating)) +
geom_point(col = "#9AC4F8", alpha = 0.5)
```

Now, that's looking much prettier. Let's add proper x- and y-axis labels as well as title.

```
##########################################################
#                     ADD AXIS LABELS
##########################################################
ggplot(data = books_sub, mapping = aes(x = book.length, y = rating)) +
  geom_point(col = "#9AC4F8", alpha = 0.5) + 
  labs(x = "Book Length (Pages)", y = "Rating", title = "Book Length vs. Rating")
```
We can even draw a trend line like we did in base R, but with much more fluidity in `ggplot2`. Conveniently, `ggplot2` defaults to providing a gray shaded area around the line. This gray shaded area represents a 95% confidence interval. 

```
##########################################################
#                     ADD A TREND LINE
##########################################################
ggplot(data = books_sub, mapping = aes(x = book.length, y = rating)) +
  geom_point(col = "#9AC4F8", alpha = 0.5) + 
  labs(x = "Book Length (Pages)", y = "Rating", title = "Book Length vs. Rating") + geom_smooth(method = "lm", col = purple)
```

Using `ggplot2` we can color our points by a continuous variable like release year.

```
##########################################################
#            COLOR BY A CONTINUOUS VARIABLE
##########################################################
library(viridis)
ggplot(data = books_sub, mapping = aes(x = book.length, y = rating, colour = release.year)) +
  geom_point(alpha = 0.5) + 
  labs(x = "Book Length (Pages)", y = "Rating", title = "Book Length vs. Rating") + 
  geom_smooth(method = "lm", col = "purple") + scale_colour_viridis() +
  geom_text(aes(label=ifelse(release.year>2015,as.character(rowname(books_sub)),'')),hjust=0,vjust=0)
```

We can label certain points in our scatter plot with ggplot2. In the below example, we are labeling all of the books with page lengths greater than 1000.

```
##########################################################
#                       LABEL POINTS
##########################################################
ggplot(data = books_sub, mapping = aes(x = book.length, y = rating, colour = release.year)) +
  geom_point(alpha = 0.5) + 
  labs(x = "Book Length (Pages)", y = "Rating", title = "Book Length vs. Rating") + 
  geom_smooth(method = "lm", col = "purple") + scale_colour_viridis() +
  geom_text(aes(label=ifelse(book.length>1000, rownames(books_sub), '')), hjust=1.01, vjust=0.25, col = "black")

```

By this point you are gaining an understanding of just how flexible ggplot2 can be. Let's get into the meat and potatoes of this lecture, shall we? Recall the question we asked ourselves at the top of the lecture:

* Do longer books get better ratings?

It is important that we keep these questions in mind when we are creating visualizations. Let's create a visualization to try and answer the first question in our list: Do longer boks get better ratings? Based on this question we will want to generate a visualization from the `book.length` and `rating` variables. Recall from using our `str()` function that `book.length` is coded as an integer and `rating` is coded as a numeric. While we could keep both variables as continuous, let's convert `book.length` to a categorical variable by binning each book into a quartile based on the number of pages. `ggplot2` provides us functionality to do just this using the `cat_number()` function. Take a look at how we are using this function below. The `n=4` indicates that I want to bin the `book.length` variable into four categories.

```
##########################################################
#                      SET UP GGPLOT
##########################################################
ggplot(books, aes(x = cut_number(book.length, n = 4), 
                           y = rating))
```

Now that we have decided on exactly what kind of data we want to input into our plot, we should take some time to consider what kind of plot(s) we would like to generate. We could go about plotting only the average rating for each of the four categories, but that doesn't give us a robust idea of all of the ratings. Instead, we might consider creating a violin plot that will show us the distribution of the ratings for each of the four book length quartiles. Take a look at the below code. If you were just looking at this data for the first time, what would you take away from this plot? What else would you want to know?

```
##########################################################
#                CREATE BASIC VIOLIN PLOT
##########################################################
ggplot(books, aes(x = cut_number(book.length, n = 4), 
                  y = rating)) +
  geom_violin(fill = "#068D9D") + ## Add violin plot
  labs(x = "Book Length (Pages)", ## Add labels
       y = "Rating", 
       title = "Book Length Quantiles \nand Their Ratings") +
       ##Change the names of the x-axis labels to be pretty
  scale_x_discrete(labels= c("0-320", "321-369","370-416", "417-1040", "NA")) +
  ## Interesting.... what is this?
  theme_minimal()
```

You may have noticed in the code above that we added `theme_minimal()`. `ggplot2` provides custom [themes](https://ggplot2.tidyverse.org/reference/ggtheme.html) with different colored background and fonts from which you can choose. You can even create your own themes or edit existing themes to your liking. Use the link above to explore a different theme!

```
##########################################################
#                EXPLORING A DIFFERENT THEME
##########################################################
ggplot(books, aes(x = cut_number(book.length, n = 4), 
                  y = rating)) +
  geom_violin(fill = "#068D9D") + ## Add violin plot
  labs(x = "Book Length (Pages)", ## Add labels
       y = "Rating", 
       title = "Book Length Quantiles \nand Their Ratings") +
       ##Change the names of the x-axis labels to be pretty
  scale_x_discrete(labels= c("0-320", "321-369","370-416", "417-1040", "NA")) +
  ## Interesting.... what is this?
  theme_bw()
```

Returning to the content of the visualization itself, the violin plots give us a decent understanding of the distribution of our data and if I squint just right I can convince myself that booking rating increases with book length. This visualization could use a bit more detail to help us answer our question. I personally would like to know about the summary statistics associated with the ratings for each of the book length quartiles. One visualization I know of that will display summary statistics is a box plot. `ggplot2` box plots show the median, the 25th percentile (Q1), the 75th percentile (Q3), the minimum and maximum, as well as any outliers. Let's overlay the violin plot we already generated with the box plot. 

```
##########################################################
#          ADDING A BOX PLOT ON THE VIOLIN PLOT
##########################################################

ggplot(books, aes(x = cut_number(book.length, n = 4), 
                  y = rating)) +
  geom_violin(fill = "#068D9D", alpha = 0.5) + ## Changed the transparency of the violin plot so its prettier.
  geom_boxplot(fill = "#53599A", width = 0.35) + ## Add box plot. Make sure to change the width of the box plot so it fits within the violin plot!
labs(x = "Book Length (Pages)", ## Add labels
     y = "Rating", 
     title = "Book Length Quantiles \nand Their Ratings") +
  ##Change the names of the x-axis labels to be pretty
  scale_x_discrete(labels= c("0-320", "321-369","370-416", "417-1040", "NA")) +
  theme_bw()
```

This is looking a bit more interesting! I can see from the medians in the box plot that there seem to be increases in ratings as book length increases. Perhaps the number of ratings could be skewing these results and making it look like longer books have higher ratings. For example, let's say there are 100 ratings for the 0-320 category and only two ratings for the 417-1040 category. The 100 ratings have a greater range of higher and lower ratings and it is entirely possible that the two ratings for the 417-1040 category are super high. We can take a look at the number of ratings in each category by placing a jitter over each of the violin and box plots. The `geom_jitter()` function in `ggplot2()` gives us this exact functionality. Take a look at the code below and notice how many ratings have been recorded for each category.

```
##########################################################
#               ADDING A JITTER TO THE PLOT
##########################################################
ggplot(books, aes(x = cut_number(book.length, n = 4), 
                  y = rating)) +
  geom_violin(fill = "#068D9D", alpha = 0.5) + 
  geom_boxplot(fill = "#53599A", width = 0.35) + 
  geom_jitter(color = "black", 
              alpha = 0.5, width = 0.2) + ## This jitter 
labs(x = "Book Length (Pages)", ## Add labels
     y = "Rating", 
     title = "Book Length Quantiles \nand Their Ratings") +
  ##Change the names of the x-axis labels to be pretty
  scale_x_discrete(labels= c("0-320", "321-369","370-416", "417-1040", "NA")) +
  theme_bw()
```
Cool! I can now see that there are about the same number of ratings for each of the categories not including the "NA" category. The increase in ratings across book length categories that we are seeing is looking like it might be real based on our visualization. However, recall that the histogram of the ratings we geneated earlier in the lecture indicate that the ratings follow a normal distribution and therefore, the mean might be a better summary statistic for our data. Let's add the mean rating for each of the book length categories to the plot as a simple red point using the `stat_summary()` function provided by `ggplot2`. Take a look at the below code. Do you see increases in average rating?

```
##########################################################
#               ADDING MEAN POINT TO THE PLOT
##########################################################
ggplot(books, aes(x = cut_number(book.length, n = 4), 
                  y = rating)) +
  geom_violin(fill = "#068D9D", alpha = 0.5) + 
  geom_boxplot(fill = "#53599A", width = 0.35) + 
  geom_jitter(color = "black", 
              alpha = 0.5, width = 0.2) +
  stat_summary(fun = "mean", 
               geom = "point", 
               color = "red", 
               size = 3) +
  labs(x = "Book Length (Pages)", ## Add labels
       y = "Rating", 
       title = "Book Length Quantiles \nand Their Ratings") +
  ##Change the names of the x-axis labels to be pretty
  scale_x_discrete(labels= c("0-320", "321-369","370-416", "417-1040", "NA")) +
  theme_bw()
```

Given that we do seem to be seeing an increase in book rating and book length, I'd like to make a determination if the inceases we are seeing between book length categories are statistically significant. While this workship is not intended to provide a comprehensive overview of statistical testing we will implement nonparametric testing to determine significance. The nonparametric test we will be using is the Wilcox Rank Sum test and it does not require that you know the distribution of your data, but it does require that your data be independent. We can plot the results of the significance testing directly on the plot using the `ggpubr()` function `stat_compare_means()`. Make sure to indicate which comparisons you would like to test!

```
##########################################################
#             ADD STATISTICAL TESTING RESULTS
##########################################################
library(ggpubr)
ggplot(books, aes(x = cut_number(book.length, n = 4), 
                  y = rating)) +
  geom_violin(fill = "#068D9D", alpha = 0.5) + 
  geom_boxplot(fill = "#53599A", width = 0.35) + 
  geom_jitter(color = "black", 
              alpha = 0.5, width = 0.2) +
  stat_summary(fun = "mean", 
               geom = "point", 
               color = "red", 
               size = 3) +
  labs(x = "Book Length (Pages)", ## Add labels
       y = "Rating", 
       title = "Book Length Quantiles \nand Their Ratings") +
  ##Change the names of the x-axis labels to be pretty
  scale_x_discrete(labels= c("0-320", "321-369","370-416", "417-1040", "NA")) +
  theme_bw() +
  stat_compare_means(comparisons = list(c("[10,320]", "(320,369]"), 
                                 c("(320,369]", "(369,416]"), 
                                 c("(369,416]", "(416,1.04e+03]")),
              test = "wilcox.test",
              textsize = 4)
```

Nicely done! It looks like there exists a statistically significant change in book rating between the 370-416 and 417-1040 book length categories. There look like there are slight increases in the other categories, albiet insignificant. 

**Conclusions**
--

During today's workshop we conducted exploratory data analysis on our romance novel data set to determine the content and types of data available to us. We generated plots in base R to geain a general understanding of the distribution of our data. Primarily, our focus today has been on building custom plots in `ggplot2`. While the visualizations we generated today are limited to the more "conventionally used" plots, I encourage you to check out some [online resources](https://r-graph-gallery.com/ggplot2-package.html) to see further plotting possibilities with `ggplot2`.

**Activity**
--

Take a moment to think about this question: How has the average length and quality of romance novels changed over time, and is there a relationship between these trends?

```
## Consider a dual-axis line plot (one line showing average length of book by year and the other showing average rating by year) with points.
## YOUR CODE HERE
```























