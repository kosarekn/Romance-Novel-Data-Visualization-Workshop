**Learning Objectives:**
-- 

**What Is The Goal of Data Visualization?** 
--
* **Visual Proof**: A great data visualization provides proof that our data shows what we have described in words. You can certainly take what I say at face value, but critically, you should expect me to show it to you. As scientist, we strive to be worthy of our readers' trust and data visualizations can assist with that.

* **Data Storytelling**: A picture is worth 1000 words! If you generate a great visualization it can adequately communicate many pieces of information. Let's say we are looking at trends in sales of different colored widgets: red widgets, blue widgets, green widgets, and yellow widgets. We could plot a single line showing how many people purchased widgets between 2020 and 2025 or I could plot four different lines, each for the sale of different colored widgets. Take a look at these visualizations. What do they tell us about our data? 

<div style="display: flex; justify-content: center;">
  <img src="/images/trends.png" width="1000" alt="Trend-Line">
</div>

The plot on the right shows us that the number of sales for red, blue, and green widgets increases over the 2020-2025 time period, but the sales for yellow widgets decreases! We wouldn't have known that had we not broken down or visualization by the groups within our "Color" variable. By the way, this reversal of trends when looking at subgroups of our variable is known as **Simpson's Paradox**.

* **Presentation Purposes**: A visualization will not only summarize your information, but will clearly communicate your findings in a memorable way. Humans remember things that they see! Some of my earliest memories are not auditory, but rather visual. I remember the color of shirt my Grandma wore when she came to pick me up from shool one day.

**What Makes A Good Visualization?**
--
* **Clear Titles and Axis Labels**: If you generate a histogram, please for the love of all that is good, do not title this histogram, "Histogram" with axes "X" and "Y". If you handed anyone on the street that visualization, they might say that you have made a lovely histogram. Of what? Who is to say. Descriptive titles might be something like, "Distribution of Widget Sale Between 2020-2025" with axis labels "Count" and "Frequency".

* **Clearly Distinguishable Colorblind Friendly Colors**: Choosing colors that are not easily distinguished from other another might mislead a reader. Further, 1 in 12 males are colorblind. Really. Here's a [reference](https://www.nei.nih.gov/eye-health-information/eye-conditions-and-diseases/color-blindness) for that. We will talk about how you can choose colorblind friendly colors later in this lecture.

* **Data Storytelling**: Your visualizations should tell a cohesive story. It's imperitive not to add distracting bells and whitles to your visualizations, rather, focus on the pieces of informtion you want your reader to gain. 

* **Know Your Audience**: Would you show your 5-year-old cousin the same graphic you would show your work collegue? Probably not. Gear your visualizations to the audience who will see them 

**How Can We Create Good Visualizations?**
--
* **Focus on Your Question**: When creating a plot, or series of plots, make sure to focus on our study question. Ask yourself how each figure supports the question you are trying to answer. Taken together all of the plots you generate should 

* **Focus on Your Findings**: If you want to know if more males or females purchsed green widgets, spend some time thinking about which visualization will most adequately help you find the answer to this question.

* **Use Programming**: You came to this workshop for a reason, did you not? Generating figures using a programming language will give you the power to fine tune your visualizations and step outside of conventionally used visualizations that can be generated by point and click tools. Plus, they are PRETTY. 


**What R Tools for Data Visualization Will We Learn About Today?**
* Base R: Some plotting functions, such as `hist()` and `plot()` are built into R and can be accessed without calling special libraries. These are known as base R plotting functions. During this workshop, we will use these base R plotting functions to conduct inital eploratory data analysis (EDA). 

* ggplot2: ggplot2 is a special R library that provides functionality to customize  advanced plots and figures. During today's workshop we will leverage ggplot2 to create publication-ready visualizations from our Romance Novel data set.

**Kaggle - Romance Novel Data Set**
Allow me to get up on my soap box for a moment and expound upon one of the most beautiful aspects of data science. We each bring expertise from our diverse and enriching backgrounds in Finance, Biology, Literature, Art, Anthropology, Physics, and whatever other discipline we fell in love with at the age of 7 while watching a NOVA episode. Developing our data science skills opens the door to research in any of these fields. If you have some data, you bet we can find a visualization or analysis appropriate for that data.  

On the topic of exploring data suited to our interests, I have chosen a romance novel data set for this workshop. It will come to the suprise of no one here that I am not going home and reading Dostoevsky, Thoreau, or even Austen. Nay, I go home and I read garbage. One could argue that I am consuming the equivalent of skittles for my brain and they would be entirely correct. But I am not on this planet with the strict purpose of being useful and productive. I want to enjoy sitting with my hot chocolate and my books. That said, let's take a look at the contents of the data set with which we will be working and with the aim of finding answers to the following questions:

* Who are the highest rated authors?
* What are the highest rated books?
* What book topics have the highest and lowest rating?

*Note: This data set was taken from [Kaggle](https://www.kaggle.com/datasets). Kaggle provides free access to tons of really intersting data! Take a look and play around!*

**Exploratory Data Analysis (EDA)**
--

It is vital to have a clear understanding of the contents of the data set with which we are working before jumping into data visualization. Thus, an initial exploratory data analysis (EDA) should be undertaken to determine the dimensions of the data, row names, column names, data types, and missingness. Let's go ahead and read in our data:

```
##########################################################
#                   LOADING OUR DATA
##########################################################
## Read in data
books <- read.csv("/Users/f002yt8/Documents/GitHub/Romance-Novel-Data-Visualization-Workshop/data/books.csv")

## Some titles are repeated so we will just keep one of the titles fr simplicity 
books <- books[!duplicated(books$title), ]

## Make the first column the book titles 
rownames(books) <- books[,"title"]
books <- subset(books, select = -c(title,X))

## Make sure "books" is a data frame
books <- data.frame(books)

## Let's check and make sure we read in the data correctly
head(books)
```
Now that we have loaded in our data let's have a look at the column names in our data frame. The column names typically contain the variables in our data. For this data set we can expect to find variables for book rating, book length, and author. In the same way if we were looking at a data set with patient information we might see variables for age, sex, white blood cell count, blood pressure, etc. To see the column names all we need to do it apply the function `colnames()`.

```
##########################################################
#                   DATA FRAME VARIABLES
##########################################################

## Column names for our data
colnames(books)
```

Great, for each title in our data we have informaiton on the author, release year, book length, rating, number of ratings, and a short synopsis of the book. I'm curious though, how many books are in this data set? We can use the R functions `dim()` and `str()` to gain an understanding of how much data we have.

```
##########################################################
#                 ASSESSING DATA DIMENSIONS
##########################################################

## Assessing data dimensions
dim(books)

## Taking a look at data dimensions...... and some other information
str(books)
```

Running the `dim()` function returns `1232` and `6` this is the number of rows and columns respectively. So we have 1232 books in our data frame and 6 variables, which we  previously viewed using `colnames()`. We used a second function here, `str()`. The `str()` function means "structure" and provides us with the dimensions of the data frame at the top of the output `'data.frame': 1232 obs. of  6 variables`. But what is all of this other information? The informaiton below the dimensions are previews of the information stored in the data frame. We can see that each of the rows in the output is one of the data frame variables. The data type is indicated after the colon in each row. For example, after `:` the `author`row we see the letters `chr` standing for "character" this means that the data in the `author` column in our data frame are `characters`. The `release.year`, `book.length`,and `number.of.ratings` is coded as `int` standing for "integer". The `rating` is coded as `num` or "numeric". Inserted after the data type, we can see a preview of some of the values in each of the variable columns. Taking a quick look, I can see that `book.length` contains a bunch of "NA" values. It's always good to look at missingness in our data. Let's use a few R functions to determine how many NA values we have in our data. 

```
##########################################################
#                 ASSESSING MISSINGNESS
##########################################################

## Assessing missingness using a for loop

book_columns <- colnames(books)

book_columns <- colnames(books)
for (col in book_columns){
  print(col)
  print(length(which(is.na(books[,col]) == TRUE)))
}
```
Wow! It looks like there are 601 "NA" values in the `book.length` variable. It is important to consider why this might be the case. If I were to guess, I would say that multiple versions of some of these books have been released with varying page lengths so instead of reporting multiple page lengths for differentbook versions, the authors of this data set simply left the length as "NA". In some cases, depending on the data, we might consider imputing NA values, however, this is beyond the scope of today's workshop so we will leave the data frame as is and move on to visualizations with the knowledge that the `book.length` variable has quite a bit of missingness.  

**Base R Visualizations - Let's Eyeball It**
--
At the beginnig of this lecture, I mentioned that base R has some great functions that we can use to take a cursory look at the distribution of our data. I would recommend using base R functions when you initially get a new data set and you are hoping to churn out some preliminary visualizations for your PI or group members for a project. 

*Histograms*
I'm intersted in the system used to rate books in this data set. Using the `hist()` function in base R, we can create a histogram that shows us the distribution of the ratings across all of the titles in our data frame. 

```
##########################################################
#            GENERATING A HISTOGRAM WITH BASE R
##########################################################

## Generate a hisogram of book ratings
hist(books[,"rating"])

## Let's add an appropriate main title as well as x and y axis labels
hist(books[,"rating"], main = "Rating Across All Titles", xlab = "Rating", ylab = "Frequency")

## How about we add some color to this plot
hist(books[,"rating"], main = "Rating Across All Titles", xlab = "Rating", ylab = "Frequency", col = "cornflowerblue")

## Let's get some more ganularity in the distribution
hist(books[,"rating"], main = "Rating Across All Titles", xlab = "Rating", ylab = "Frequency", col = "cornflowerblue", breaks = 30)
```

*Scatter Plot*
In addition to histograms, base R provides functionality to create scatterplots using the `plot()` function. The plot function takes a vector for x values and a vector for y values and plots them together. I'm wondering if we could see any sort of trend between book length and rating? I'll remove any values where there is "NA" for `book.length` before plotting. 

```
##########################################################
#            GENERATING A SCATTERPLOT WITH BASE R
##########################################################

## Drop any rows with NA values in the book.length column
library(tidyr)
books_sub <- books %>% drop_na(book.length)

## Set x and y
x <- books_sub[,"book.length"]
y <- books_sub[,"rating"]

## Plot book length vs. rating
plot(x, y, main = "Book Length vs. Rating", xlab = "Book length (Pages)", ylab = "Rating", col = "darkgreen")

## Increase point size
plot(x, y, main = "Book Length vs. Rating", xlab = "Book length (Pages)", ylab = "Rating", col = "darkgreen", cex = 3)

## Change the shape of the point
plot(x, y, main = "Book Length vs. Rating", xlab = "Book length (Pages)", ylab = "Rating", col = "darkgreen", pch = 25)

## I suppose I can convince myself that there is a linear relationship between rating and length of book
model <- lm(y ~ x) # define a model
abline(model, col = "red", lwd = 2)
plot(x, y, main = "Book Length vs. Rating", xlab = "Book length (Pages)", ylab = "Rating", col = "darkgreen", pch = 25)

```
*Box Plot*
An additional way in which we can explore relationships between two variables is to create a box plot. I'm interested in looking at the distribution of ratings for books between 2010 and 2014. To do so, we will subset of main data frame to contain only data from 2010-2014. We will also convert the `release.year` to a factor, which is a special case of a vector. Finally, we will add color to our box plots. On that note, I would like to introduce you all to [Coolors](https://coolors.co/?home). Coolors is a great resource to help you pick out custom color palettes for your R plots! Or they can help you pick out a new color for your bathroom walls.

```
##########################################################
#            GENERATING A BOXPLOT WITH BASE R
##########################################################

## Subset data to the years 2010-2014
books_sub <- books[which(books$release.year == c(2010, 2011, 2012, 2013, 2014)),]

## Make sure that the source year is coded as a factor
books_sub$release.year <- factor(books_sub$release.year)

## Create box plot
boxplot(rating ~ release.year, 
        data = books_sub, 
        notch = TRUE, 
        col = c("#9AC4F8", "#99EDCC","#CB958E", "#E36588", "#9A275A"),
        main = "Rating Distribution by Year",
        xlab = "Year", ylab = "Rating")

```

Base R functions are quick and easy to use. You can apply the limited number of parameters to these visualization functions and have some half way decent plots to get a general understanding of data distribution. But that's just the thing, we are quite limited to the few parameters provided by base R functions. With base R functions we are typically only able to answer simple questions about our data. However, using `ggplot2` we are able to take a layered approach to data visualization that can help us begin to get at complex questions. 

**Creating Plots with ggplot2**
--
ggplot2 is an R package that leverages a layered coding framework to create visualizations. What do we mean by a "layered coding framework"? In `ggplot2` we have the power to add elements on top of one another in our data set. For example, we might find it helpful to overlay a distribution plot on a point representing an average so that we gain a better understanding of the disribution of our data. Let's take a look at the anatomy of a `ggplot2` plot before we dive into some more complex questions.

The foundation of every `ggplot2` graphic is the data used to construct the plot. As a first step, we will need to pass our rectangular data frame to the `ggplot2 ` argument. 

```
##########################################################
#                BASE OF A GGPLOT PLOT
##########################################################

## We wil proceed downstream by looking at the subset data frame that does not contain NA values for book.length
library(tidyr)
books_sub <- books %>% drop_na(book.length)

## The base of a ggplot2 plot
ggplot(data = books_sub)
```

Now, I will happily bet a couple dollars and say that a few of you in this workshop skipped ahead, ran the above code, and said "This didn't do anything." or "This returned a gray box." You are correct! This line of code shouldn't have returned really anything because we have not specificed the variables we wish to visualize. Let's say we want to replicate the scatter plot we made in base R where we plotted the book length on the x-axis and book rating on the y-axis. 

```
##########################################################
#                     ADD VARAIABLES
##########################################################

## Add variables we would like to plot
ggplot(data = books_sub, mapping = aes(x = book.length, y = rating))
```

You may be wondering at this point, "NOELLE, I STILL DON'T SEE ANY PLOT!?!?!?!" Yes, you shouldn't see any plot quite yet because we have not told `ggplot2` what type of plot we want to generate. To indicate that we would like to create a scatter plot, we have to use the `geom_point()` function. 

```
##########################################################
#                   ADD TYPE OF PLOT
##########################################################

## Add type of plot
ggplot(data = books_sub, mapping = aes(x = book.length, y = rating)) +
geom_point()
```
Finally! We have a plot, but it's hedious. We can change the color of the points and the transparency of the points within the `geom_point()` function. 

```
##########################################################
#         CHANGING DISCRETE COLOR OF ALL POINTS
##########################################################

## Add type of plot
ggplot(data = books_sub, mapping = aes(x = book.length, y = rating)) +
geom_point(col = "#9AC4F8", alpha = 0.5)
```

Now, that's looking much prettier. Let's add proper x- and y-axis labels as well as title.

```
##########################################################
#                     ADD AXIS LABELS
##########################################################
ggplot(data = books_sub, mapping = aes(x = book.length, y = rating)) +
  geom_point(col = "#9AC4F8", alpha = 0.5) + 
  labs(x = "Book Length (Pages)", y = "Rating", title = "Book Length vs. Rating")
```
We can even draw a trend line like we did in base R, but with much more fluidity in `ggplot2`. Conveniently, `ggplot2` defaults to providing a gray shaded area around the line. This gray shaded area represents a 95% confidence interval. 

```
##########################################################
#                     ADD A TREND LINE
##########################################################
ggplot(data = books_sub, mapping = aes(x = book.length, y = rating)) +
  geom_point(col = "#9AC4F8", alpha = 0.5) + 
  labs(x = "Book Length (Pages)", y = "Rating", title = "Book Length vs. Rating") + geom_smooth(method = "lm", col = purple)
```

Using `ggplot2` we can color our points by a continuous variable like release year.

```
##########################################################
#            COLOR BY A CONTINUOUS VARIABLE
##########################################################
library(viridis)
ggplot(data = books_sub, mapping = aes(x = book.length, y = rating, colour = release.year)) +
  geom_point(alpha = 0.5) + 
  labs(x = "Book Length (Pages)", y = "Rating", title = "Book Length vs. Rating") + 
  geom_smooth(method = "lm", col = "purple") + scale_colour_viridis() +
  geom_text(aes(label=ifelse(release.year>2015,as.character(rowname(books_sub)),'')),hjust=0,vjust=0)
```

We can label certain points in our scatter plot with ggplot2. In the below example, we are labeling all of the books with page lengths greater than 1000.

```
##########################################################
#                       LABEL POINTS
##########################################################
ggplot(data = books_sub, mapping = aes(x = book.length, y = rating, colour = release.year)) +
  geom_point(alpha = 0.5) + 
  labs(x = "Book Length (Pages)", y = "Rating", title = "Book Length vs. Rating") + 
  geom_smooth(method = "lm", col = "purple") + scale_colour_viridis() +
  geom_text(aes(label=ifelse(book.length>1000, rownames(books_sub), '')), hjust=1.01, vjust=0.25, col = "black")

```

By this point you are gaining an understanding of just how flexible ggplot2 can be. Let's get into the meat and potatoes of this lecture, shall we? Recall those questions we asked ourselves at the top of the lecture:

* Who are the highest rated authors?
* What are the highest rated books?
* What book topics have the highest and lowest rating?

It is important that we keep these questions in mind when we are creating visualizations. Let's create a visualization to try and answer the first question in our list: Who are the highest rated authors? 































